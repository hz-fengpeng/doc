@startuml

class AVFormatContext{
    const AVClass *av_class;
    //音视频容器格式有关
   const struct AVInputFormat *iformat;
   const struct AVOutputFormat *oformat;
   AVIOContext *pb;
   unsigned int nb_streams;  // 流的个数
   AVStream **streams;      // 里面有AVCodecContext，编解码信息
   void *priv_data; // 各种格式的私有数据,从AVInputFormat中拷贝，如MOVContext*, WAVDemuxContext*
   const AVCodec *video_codec; // 视频解码器
   const AVCodec *audio_codec;  // 音频解码器
   int (*io_open)(struct AVFormatContext *s, AVIOContext **pb, const char *url,
                   int flags, AVDictionary **options);// 默认为io_open_default,打开文件函数
    
    void (*io_close)(struct AVFormatContext *s, AVIOContext *pb); // 默认为io_close_default函数，文件关闭函数
}

class AVInputFormat{
    // 输入的容器格式相关
    const char *name;
    const char *extensions;
    int priv_data_size; //格式的私有数据，如sizeof(MOVContext)
    const AVClass *priv_class;  //私有类，如mov_class
    int (*read_probe)(const AVProbeData *);
    int (*read_header)(struct AVFormatContext *);
}

class AVIOContext{
    //管理输入输出数据的结构,可通过URLContext生成
    void *opaque; // URLContext指针
    unsigned char *buffer;  /**< Start of the buffer. */
    int buffer_size;        /**< Maximum buffer size */   // 根据URLContext得到
    int (*read_packet)(void *opaque, uint8_t *buf, int buf_size);   // 初始化为ffurl_read, 最后会调用URLProtocol中的url_read
    int (*write_packet)(void *opaque, uint8_t *buf, int buf_size);  // 初始化为ffurl_write
    int64_t (*seek)(void *opaque, int64_t offset, int whence);      // 初始化为ffrul_seek
}

class URLContext{
' 找到URLProtocol后，分配新的URLContext, 将URLProtocol的值赋值给URLContext
    void *priv_data;//用于存储各种协议的数据，\n比如FILE文件时保存FileContext，里面存放了文件指针
    const struct URLProtocol *prot;
}

class URLProtocol{
    '封装各种协议的基本操作如 FILE*，UDP，RTP
    int     (*url_open)( URLContext *h, const char *url, int flags);
    int     (*url_read)( URLContext *h, unsigned char *buf, int size);
    int     (*url_write)(URLContext *h, const unsigned char *buf, int size);
    int     (*url_close)(URLContext *h);
}

class AVStream{
    '存储每一个视频/音频流信息的结构体
    int index; // 标识该视频/音频流
    int id;
    void *priv_data;  // 指向该视频/音频流的AVCodecContex
    AVRational time_base; // 时基
    AVDictionary *metadata; // 元数据
    AVRational avg_frame_rate;  // 帧率
    AVPacket attached_pic; // 附带的图片
    AVCodecParameters *codecpar; // 编解码参数, 声道数，编码值，采样率等
    AVStreamInternal *internal; // 里面有AVCodecContext
}

class AVCodecContext{
    '编解码器信息，根据AVCodec进行赋值
    const struct AVCodec  *codec;
    void *priv_data;    // 编解码器私有数据
    int channels;   // 音频通道
    int sample_rate;    // 采样率
    enum AVSampleFormat sample_fmt;  ///< sample format

}

class AVCodec{
    '编解码器，与AVCodecContext对应
     int (*init)(struct AVCodecContext *);  // 编码器初始化
      int (*decode)(struct AVCodecContext *avctx, void *outdata,
                  int *got_frame_ptr, struct AVPacket *avpkt);  // 解码

}

class AVPacket{
    '存储压缩编码数据相关信息
    uint8_t *data; // 压缩编码的数据，可能不是
    int   size; // 数据大小
}

class AVFrame{
    //AVPacket解码后生成AVFrame, 用于存储原始数据
    uint8_t *data[AV_NUM_DATA_POINTERS];
}

@enduml

ffmpeg中的结构体成功管理系统
AVClass, AVOption
AVClass 放在结构体的第一个位置。调用av_opt_set或av_opt_get来进行结构体里字段的赋值。
主要是根据传入的参数，找到该参数在结构体中的位置，最后进行赋值。

avctx->priv_data = av_mallocz(codec->priv_data_size);
*(const AVClass **)avctx->priv_data = codec->priv_class;
以h264_nvenc编码器为例，在上层是这样赋值给私有指针priv
(const AVClass*)s->priv_data = codec->priv_class;
其中s是结构体AVCodecContext，codec是结构体AVCodec，codec->priv_class是h264_nvenc_class,这个class关键是保存了options信息

根据偏移量，也就是记录NvencContext 每个成员的相对偏移地址，并在这个地址进行赋值操作，然后在具体的底层（插件）代码中：
NvencContext *ctx = avctx->priv_data;
这样就确定了NvencContext每个成员 相对的地址的偏移量，每个NvencContext 的数据成员值就确定了

内核+插件

@startuml

'AVPacket和AVFrame内部都封装了AVBufferRef
'AVBufferRef真正存储数据的是AVBuffer
'AVBuffer的data是真正存数据的，refcount是引用计数

AVBuffer <|-- AVBufferRef
AVBufferRef <|-- AVPacket
AVBufferRef <|-- AVFrame

class AVBuffer
{
    uint8_t *data
    size_t size;
    atomic_uint refcount; // 引用计数

}

class AVBufferRef
{
    AVBuffer *buffer;
    uint8_t *data;  // == AVBuffer::data 
    int size;
}

class AVPacket
{

    AVBufferRef *buf; // 管理引用计数
    uint8_t *data;  // == AVBuffer::data 
    int64_t pts;  //显示时间
    int64_t dts;  //解码时间
    int   size;   // 包大小 
    int64_t duration;  // 数据时长
    int64_t pos;  // 在流媒体中的位置
}

class AVFrame
{
    AVBufferRef *buf[AV_NUM_DATA_POINTERS];
}

class AVBufferPool
{
    // AVBuffer内存池
    AVMutex mutex;
    BufferPoolEntry *pool;

    atomic_uint refcount;

    size_t size;
    void *opaque;
    AVBufferRef* (*alloc)(size_t size);
    AVBufferRef* (*alloc2)(void *opaque, size_t size);
    void         (*pool_free)(void *opaque);
}

class BufferPoolEntry
{
    uint8_t *data;
    void *opaque;
    void (*free)(void *opaque, uint8_t *data);

    AVBufferPool *pool;
    struct BufferPoolEntry *next;
}

@enduml

```

不同的AVPacket有自己的AVBufferRef，但可能共用AVBuffer
对于多个AVPacket共享同一个缓存空间， FFmpeg使用的引用计数的机制（reference-count） ：

初始化引用计数为0，只有真正分配AVBuffer的时候，引用计数初始化为1;
当有新的Packet引用共享的缓存空间时， 就将引用计数+1；
当释放了引用共享空间的Packet，就将引用计数-1；引用计数为0时，就释放掉引用的缓存空间AVBuffer。
AVFrame也是采用同样的机制

```

AVPacket *av_packet_alloc(void);	分配AVPacket，这个时候和buffer没有关系, 和AVBufferRef没关系
void av_init_packet(AVPacket *pkt);	初始化AVPacket，只是单纯初始化pkt字段， 和AVBufferRef没关系

int av_new_packet(AVPacket *pkt, int size);	给AVPacket的AVBufferRef分配内存， 引用计数初始化为1

int av_packet_ref(AVPacket *dst, const AVPacket *src);	增加引用计数

void av_packet_unref(AVPacket *pkt);	释放AVBufferRef，减少引用计数, 如果计数减到1

void av_packet_move_ref(AVPacket *dst, AVPacket *src);	转移引用计数，同时初始化src
AVPacket *av_packet_clone(const AVPacket *src);	等于av_packet_alloc()+av_packet_ref()

void av_packet_free(AVPacket **pkt);	释放AVPacket和_alloc对应


读包时，只需要调用av_packet_alloc，然后调用av_read_frame来取包。不需要考虑AVBufferRef。


 
 ```
 外部库调用ffmpeg解码，vlc里操作
    1. AVPacket *pkt = av_packet_alloc(); 申请一个AVPacket
    2.  赋值pkt里的变量，似乎不考虑AVBufferRef。
        pkt->data 
        pkt->size 
        pkt->pts 
        pkt->dts 
        p_block->i_pts =
        p_block->i_dts = 
    3.  给解码器发送包
        ret = avcodec_send_packet(p_context, pkt);
    4.  释放pkt。
        av_packet_free( &pkt );

    5. AVFrame *frame = av_frame_alloc();  申请AVFrame
    6. ret = avcodec_receive_frame(p_context, frame);  // 接收AVFrame
        memcpy
    7. av_frame_free(&frame); // 释放frame 

 ```

```

流结束的情况
文件流结束后都需要“刷新”(也叫draining)编解码器，因为编解码器可能出于性能考虑或由于必须的原因(比如考虑b帧时)会在内部缓冲多个帧或包，为了拿到这些剩余的数据，处理方法如下：

文件结束时，将NULL(而不是有效的输入，具体来说比如解码时将输入的packet设置为：pkt->data = NULL;pkt->size = 0;)发送到avcodec_send_packet()(解码时)或avcodec_send_frame()(编码时)函数，这将进入draining模式。

在循环中调用avcodec_receive_frame()(解码)或avcodec_receive_packet()(编码)时，加入对返回值是否是AVERROR_EOF的判断。当输入NULL进入draining模式后将会返回AVERROR_EOF而不会返回AVERROR(EAGAIN)。

捕获AVERROR_EOF后，调用avcodec_flush_buffers()刷新编解码器使得可以恢复重新解码
```




@startuml

class MyAVPacketList
{
    AVPacket *pkt; // 放的是指针
    int serial;
}

class AVFifoBuffer
{   
    // 队列
    uint8_t *buffer;
    uint8_t *rptr, *wptr, *end;
    uint32_t rndx, wndx;
}

class PacketQueue
{
    AVFifoBuffer *pkt_list;
    int nb_packets;
    int size;
    int64_t duration;
    int abort_request;
    int serial;
}
@enduml

ffmpeg中的packet队列
AVPacket队列  int packet_queue_put(PacketQueue *q, AVPacket *pkt)
在函数里调用av_packet_alloc生成pkt1, 然后调用av_packet_move_ref, 将pkt移动到pkt1.
此时，pkt里的AVBufferRef设置为NULL.
相当于重新生成了AVPacket, 放在队列里也只是指针。

从队列中取包, 从队列中取出指针AVPacket*. 然后调用av_packet_move_ref，将队列中的指针AVPacket*里的内容
转移到pkt中，同时调用av_packet_free释放队列中的AVPacket*。
取出AVPacket后，发送给解码器后，调用av_packet_unref(), 将AVPacket引用计数减一。

ffmpeg里的内存池 pool_release_buffer
在解码时，会用到内存池。
av_buffer_pool_init；初始化内存池
av_buffer_pool_get；从内存池中取一个AVBufferRef

内存池中的AVBufferRef是以BufferPoolEntry连成一个链表
每个buffer的大小都是一样的。就是这个内存池只能放一种类型

pool_release_buffer；将内存还给内存池
av_buffer_pool_uninit；释放内存池
内存池在初始化解码器时会初始化，在解码器释放后会销毁。


AVFrame常用API
函数原型	说明
AVFrame *av_frame_alloc(void);	分配AVFrame
void av_frame_free(AVFrame **frame);	释放AVFrame
int av_frame_ref(AVFrame *dst, const AVFrame *src);	增加引用计数
void av_frame_unref(AVFrame *frame);	减少引用计数
void av_frame_move_ref(AVFrame *dst, AVFrame *src);	转移引用计数
int av_frame_get_buffer(AVFrame *frame, int align);	根据AVFrame分配内存
AVFrame *av_frame_clone(const AVFrame *src);	等于av_frame_alloc()+av_frame_ref()

对于视频（Video）来说，AVPacket通常包含一个压缩的Frame；
而音频（Audio）则有可能包含多个压缩的Frame。
并且，一个packet也有可能是空的，不包含任何压缩数据data，只含有边缘数据side data


has_codec_parameters
    ffmpeg解码器需要的参数
    音频：
        1. frame_size.   帧长，没有固定帧长的码型不需要
        2. sample_fmt.   采样格式，每个采样点的位数。 如：AV_SAMPLE_FMT_S16, ///< signed 16 bits
        3. sample_rate.  采样率 8000
        4. channels.     声道数。
        5. 码型.          pcma 
    视频：
        1. width